function tokenizer(t,e){function n(t){return"\n"!=t&&/^[\s\u00a0]*$/.test(t)}var i={state:e,take:function(e){return"string"==typeof e&&(e={style:e,type:e}),e.content=(e.content||"")+t.get(),/\n$/.test(e.content)||t.nextWhile(n),e.value=e.content+t.get(),e},next:function(){if(!t.more())throw StopIteration;var e;if(t.equals("\n"))return t.next(),this.take("whitespace");if(t.applies(n))e="whitespace";else for(;!e;)e=this.state(t,function(t){i.state=t});return this.take(e)}};return i}